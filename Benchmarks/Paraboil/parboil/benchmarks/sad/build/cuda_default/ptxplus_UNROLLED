//HEADER
.version 1.4+
.target sm_10, map_f64_to_f32
//END HEADER


//INSTRUCTIONS

.const .u32 constant1_Z18larger_sad_calc_16Ptii[1] = {
          0x00000220
};

.const .u32 constant1_Z17larger_sad_calc_8Ptii[5] = {
          0x000003ff, 0x00000063, 0x00000001, 0x00000220, 
          0x00000019
};






.entry  _Z17larger_sad_calc_8Ptii (
	.param  .u64 __cudaparm__Z17larger_sad_calc_8Ptii_blk_sad ,
	.param  .s32 __cudaparm__Z17larger_sad_calc_8Ptii_mb_width ,
	.param  .s32 __cudaparm__Z17larger_sad_calc_8Ptii_mb_height )
{
	.reg .u32 $r<13>;
	.reg .pred $p<4>;

	.reg .u32 $o127;

	
	and.u16 $r1.lo, $r0.hi, constant1_Z17larger_sad_calc_8Ptii[0x0000];
	cvt.u32.u16 $r1, $r1.lo;
	shr.u32 $r9, $r1, 0x00000001;
	set.gt.s32.s32 $p0/$o127, $r9, constant1_Z17larger_sad_calc_8Ptii[0x0004];
	ssy 0x00000150;
	@$p0.ne bra l0x00000150;
	and.u16 $r1.lo, $r0.hi, constant1_Z17larger_sad_calc_8Ptii[0x0000];
	cvt.u32.u16 $r2, $r1.lo;
	mov.u32 $r1, s[0x0018];
	shl.u32 $r5, $r9, 0x00000002;
	and.b32 $r2, $r2, constant1_Z17larger_sad_calc_8Ptii[0x0008];
	shl.u32 $r3, $r9, 0x00000001;
	mul24.lo.u32 $r4, s[0x001c], $r1;
	add.half.u32 $r6, $r2, $r5;
	add.u32 $r3, $r2, $r3;
	shl.u32 $r7, $r4, 0x00000003;
	shl.u32 $r5, $r4, 0x00000002;
	cvt.u32.u16 $r1, %ctaid.y;
	cvt.u32.u16 $r2, %ctaid.x;
	add.half.u32 $r7, $r4, $r7;
	add.half.u32 $r4, $r4, $r5;
	mad24.lo.s32 $r1, s[0x0018], $r1, $r2;
	add.half.u32 $r6, $r6, $r7;
	add.half.u32 $r3, $r3, $r4;
	mov.u32 $r5, 0x00002240;
	mov.u32 $r4, 0x00000448;
	mov.u32 $r2, 0x00001120;
	mul.half.lo.u16 $r10, $r1.lo, $r5.hi;
	mul.half.lo.u16 $r11, $r4.hi, $r6.lo;
	mul.half.lo.u16 $r7, $r1.lo, $r2.hi;
	mul.half.lo.u16 $r8, $r3.lo, $r4.hi;
	mad.wide.u16 $r10, $r1.hi, $r5.lo, $r10;
	mad.wide.u16 $r11, $r4.lo, $r6.hi, $r11;
	mad.wide.u16 $r7, $r1.hi, $r2.lo, $r7;
	mad.wide.u16 $r8, $r3.hi, $r4.lo, $r8;
	shl.u32 $r10, $r10, 0x00000010;
	shl.u32 $r11, $r11, 0x00000010;
	shl.u32 $r7, $r7, 0x00000010;
	shl.u32 $r8, $r8, 0x00000010;
	mad.wide.u16 $r5, $r1.lo, $r5.lo, $r10;
	mad.wide.u16 $r6, $r4.lo, $r6.lo, $r11;
	mad.wide.u16 $r1, $r1.lo, $r2.lo, $r7;
	mad.wide.u16 $r2, $r3.lo, $r4.lo, $r8;
	add.half.u32 $r3, $r5, $r6;
	add.half.u32 $r1, $r1, $r2;
	shl.u32 $r2, $r3, 0x00000001;
	shl.u32 $r1, $r1, 0x00000001;
	add.half.u32 $r8, s[0x0010], $r2;
	add.half.u32 $r7, s[0x0010], $r1;
	l0x00000150: cvt.u32.u16 $r1, $r0.lo;
	set.gt.s32.s32 $p0/$o127, $r1, constant1_Z17larger_sad_calc_8Ptii[0x000c];
	@$p0.ne retp;
	and.u16 $r2.lo, $r0.hi, constant1_Z17larger_sad_calc_8Ptii[0x0000];
	mov.u32 $r0, s[0x0018];
	cvt.u32.u16 $r2, $r2.lo;
	shl.u32 $r5, $r9, 0x00000002;
	mul24.lo.u32 $r3, s[0x001c], $r0;
	and.b32 $r4, $r2, constant1_Z17larger_sad_calc_8Ptii[0x0008];
	shl.u32 $r2, $r9, 0x00000001;
	shl.u32 $r0, $r3, 0x00000004;
	add.half.u32 $r5, $r4, $r5;
	add.half.u32 $r2, $r2, $r4;
	cvt.u32.u16 $r6, %ctaid.y;
	cvt.u32.u16 $r9, %ctaid.x;
	add.u32 $r4, $r0, $r3;
	shl.u32 $r0, $r5, 0x00000001;
	shl.u32 $r5, $r2, 0x00000001;
	mad24.lo.s32 $r2, s[0x0018], $r6, $r9;
	mad24.lo.s32 $r0, $r3, constant1_Z17larger_sad_calc_8Ptii[0x0010], $r0;
	add.u32 $r3, $r4, $r5;
	mov.u32 $r6, 0x00004480;
	mov.u32 $r4, 0x00000448;
	mov.u32 $r5, 0x00002240;
	mul.half.lo.u16 $r11, $r2.lo, $r6.hi;
	mul.half.lo.u16 $r12, $r4.hi, $r0.lo;
	mul.half.lo.u16 $r9, $r3.lo, $r4.hi;
	mul.half.lo.u16 $r10, $r2.lo, $r5.hi;
	mad.wide.u16 $r11, $r2.hi, $r6.lo, $r11;
	mad.wide.u16 $r12, $r4.lo, $r0.hi, $r12;
	mad.wide.u16 $r9, $r3.hi, $r4.lo, $r9;
	mad.wide.u16 $r10, $r2.hi, $r5.lo, $r10;
	shl.u32 $r11, $r11, 0x00000010;
	shl.u32 $r12, $r12, 0x00000010;
	shl.u32 $r9, $r9, 0x00000010;
	shl.u32 $r10, $r10, 0x00000010;
	mad.wide.u16 $r6, $r2.lo, $r6.lo, $r11;
	mad.wide.u16 $r11, $r4.lo, $r0.lo, $r12;
	mad.wide.u16 $r0, $r3.lo, $r4.lo, $r9;
	mad.wide.u16 $r2, $r2.lo, $r5.lo, $r10;
	add.half.u32 $r3, $r6, $r11;
	add.half.u32 $r0, $r0, $r2;
	shl.u32 $r2, $r3, 0x00000001;
	shl.u32 $r0, $r0, 0x00000001;
	shl.u32 $r4, $r1, 0x00000002;
	add.half.u32 $r3, s[0x0010], $r2;
	add.half.u32 $r5, s[0x0010], $r0;
	add.half.u32 $r0, $r4, $r8;
	add.half.u32 $r2, $r4, $r7;
	add.half.u32 $r3, $r4, $r3;
	add.half.u32 $r4, $r4, $r5;
	l0x000002b0: ld.global.u32 $r5, [$r3];
	add.u32 $r6, $r3, 0x00002240;
	ld.global.u32 $r6, [$r6];
	add.u32 $r7, $r3, 0x00000890;
	ld.global.u32 $r8, [$r7];
	add.u32 $r7, $r3, 0x00002ad0;
	ld.global.u32 $r7, [$r7];
	add.u32 $r9, $r5, $r6;
	st.global.u32 [$r4], $r9;
	add.u32 $r10, $r4, 0x00000890;
	add.half.u32 $r9, $r8, $r7;
	add.half.u32 $r5, $r5, $r8;
	st.global.u32 [$r10], $r9;
	add.u32 $r6, $r6, $r7;
	add.u32 $r7, $r0, 0x00001120;
	st.global.u32 [$r0], $r5;
	add.u32 $r5, $r5, $r6;
	st.global.u32 [$r7], $r6;
	add.u32 $r1, $r1, 0x00000020;
	st.global.u32 [$r2], $r5;
	add.u32 $r3, $r3, 0x00000080;
	set.le.s32.s32 $p0/$o127, $r1, constant1_Z17larger_sad_calc_8Ptii[0x000c];
	add.u32 $r4, $r4, 0x00000080;
	add.u32 $r0, $r0, 0x00000080;
	add.u32 $r2, $r2, 0x00000080;
	@$p0.ne bra l0x000002b0;
	nop;

	l_exit: exit;
}

.entry  _Z18larger_sad_calc_16Ptii (
	.param  .u64 __cudaparm__Z18larger_sad_calc_16Ptii_blk_sad ,
	.param  .s32 __cudaparm__Z18larger_sad_calc_16Ptii_mb_width ,
	.param  .s32 __cudaparm__Z18larger_sad_calc_16Ptii_mb_height )
{
	.reg .u32 $r<11>;
	.reg .pred $p<4>;

	.reg .u32 $o127;

	
	cvt.u32.u16 $r0, $r0.lo;
	set.gt.s32.s32 $p0/$o127, $r0, constant1_Z18larger_sad_calc_16Ptii[0x0000];
	@$p0.ne retp;
	cvt.u32.u16 $r2, %ctaid.y;
	cvt.u32.u16 $r3, %ctaid.x;
	mov.u32 $r1, s[0x0018];
	mad24.lo.s32 $r2, s[0x0018], $r2, $r3;
	mul24.lo.u32 $r5, s[0x001c], $r1;
	mov.u32 $r1, 0x00000448;
	mov.u32 $r3, 0x00000890;
	add.u32 $r4, $r5, $r2;
	mul.half.lo.u16 $r6, $r4.lo, $r1.hi;
	mul.half.lo.u16 $r7, $r1.hi, $r5.lo;
	mul.wide.u16 $r8, $r2.lo, $r3.hi;
	mad.wide.u16 $r6, $r4.hi, $r1.lo, $r6;
	mad.wide.u16 $r7, $r1.lo, $r5.hi, $r7;
	mul.wide.u16 $r9, $r1.hi, $r2.lo;
	mad.wide.u16 $r8, $r2.hi, $r3.lo, $r8;
	shl.u32 $r6, $r6, 0x00000010;
	shl.u32 $r7, $r7, 0x00000010;
	mad.wide.u16 $r9, $r1.lo, $r2.hi, $r9;
	shl.u32 $r8, $r8, 0x00000010;
	mad.wide.u16 $r6, $r4.lo, $r1.lo, $r6;
	mad.wide.u16 $r4, $r1.lo, $r5.lo, $r7;
	shl.u32 $r9, $r9, 0x00000010;
	mad.wide.u16 $r7, $r2.lo, $r3.lo, $r8;
	shl.u32 $r5, $r6, 0x00000002;
	shl.u32 $r3, $r6, 0x00000001;
	mad.wide.u16 $r8, $r1.lo, $r2.lo, $r9;
	add.half.u32 $r6, $r4, $r7;
	add.half.u32 $r2, $r4, $r5;
	add.u32 $r1, $r3, $r4;
	shl.u32 $r4, $r0, 0x00000002;
	shl.u32 $r5, $r8, 0x00000001;
	shl.u32 $r3, $r6, 0x00000001;
	shl.u32 $r2, $r2, 0x00000001;
	shl.u32 $r1, $r1, 0x00000001;
	add.half.u32 $r7, s[0x0010], $r5;
	add.half.u32 $r6, s[0x0010], $r3;
	add.half.u32 $r3, s[0x0010], $r2;
	add.half.u32 $r5, s[0x0010], $r1;
	add.half.u32 $r2, $r4, $r7;
	add.half.u32 $r1, $r4, $r6;
	add.half.u32 $r3, $r4, $r3;
	add.half.u32 $r4, $r4, $r5;
	l0x00000138: ld.global.u32 $r9, [$r3];
	add.u32 $r5, $r3, 0x00001120;
	ld.global.u32 $r5, [$r5];
	add.u32 $r6, $r3, 0x00000890;
	ld.global.u32 $r10, [$r6];
	add.u32 $r6, $r3, 0x000019b0;
	ld.global.u32 $r6, [$r6];
	add.u32 $r7, $r9, $r5;
	st.global.u32 [$r4], $r7;
	add.u32 $r7, $r4, 0x00000890;
	add.half.u32 $r8, $r10, $r6;
	add.half.u32 $r9, $r9, $r10;
	st.global.u32 [$r7], $r8;
	add.u32 $r5, $r5, $r6;
	add.u32 $r6, $r1, 0x00000890;
	st.global.u32 [$r1], $r9;
	add.u32 $r7, $r9, $r5;
	st.global.u32 [$r6], $r5;
	add.u32 $r0, $r0, 0x00000020;
	st.global.u32 [$r2], $r7;
	add.u32 $r3, $r3, 0x00000080;
	set.le.s32.s32 $p0/$o127, $r0, constant1_Z18larger_sad_calc_16Ptii[0x0000];
	add.u32 $r4, $r4, 0x00000080;
	add.u32 $r1, $r1, 0x00000080;
	add.u32 $r2, $r2, 0x00000080;
	@$p0.ne bra l0x00000138;
	nop;

	l_exit: exit;
}

.const .u32 constant1_Z11mb_sad_calcPtS_ii[13] = {
          0x0000000f, 0xfffffff0, 0x00000003, 0x00010000, 
          0xfffffffc, 0x00000441, 0x00000004, 0x00000020, 
          0x0000001f, 0x00000111, 0x00000019, 0xffffffdf, 
          0x00000001
};


.entry  _Z11mb_sad_calcPtS_ii (
	.param  .u64 __cudaparm__Z11mb_sad_calcPtS_ii___val_paramblk_sad ,
	.param  .u64 __cudaparm__Z11mb_sad_calcPtS_ii_frame ,
	.param  .s32 __cudaparm__Z11mb_sad_calcPtS_ii_mb_width ,
	.param  .s32 __cudaparm__Z11mb_sad_calcPtS_ii_mb_height )
{
	.reg .u32 $r<29>;
	.reg .u32 $ofs<2>;
	.reg .pred $p<4>;

	.reg .u32 $r124;

	.reg .u32 $o127;

	
	mov.u32 $r6, $r0;
	cvt.u32.u16 $r9, $r6.lo;
	shr.u32 $p0|$r1, $r9, 0x00000004;
	ssy 0x00000168;
	cvt.u32.u16 $r10, %ctaid.y;
	cvt.u32.u16 $r0, %ctaid.x;
	@$p0.ne bra l0x00000160;
	add.u32 $r1, $r10, $r1;
	shl.u32 $r2, $r1, 0x00000002;
	shr.s32 $r2, $r2, 0x00000004;
	shl.u32 $r3, $r0, 0x00000002;
	set.gt.s32.s32 $p0/$o127, s[0x0024], $r2;
	shr.s32 $r2, $r3, 0x00000004;
	@$p0.ne set.gt.s32.s32 $p0/$o127, s[0x0020], $r2;
	ssy 0x00000150;
	mov.u32 $r8, $r0;
	@$p0.eq bra l0x00000150;
	cvt.u32.u16 $r2, $r6.lo;
	shr.s32 $r3, $r2, 0x00000002;
	shl.u32 $r5, $r1, 0x00000002;
	mov.u32 $r1, s[0x0020];
	and.b32 $r3, $r3, constant1_Z11mb_sad_calcPtS_ii[0x0008];
	mul.half.lo.u16 $r4, $r1.lo, $r3.hi;
	mul.half.lo.u16 $r7, $r1.lo, $r5.hi;
	mad.wide.u16 $r4, $r1.hi, $r3.lo, $r4;
	mad.wide.u16 $r7, $r1.hi, $r5.lo, $r7;
	shl.u32 $r4, $r4, 0x00000010;
	shl.u32 $r7, $r7, 0x00000010;
	mad.wide.u16 $r3, $r1.lo, $r3.lo, $r4;
	mad.wide.u16 $r5, $r1.lo, $r5.lo, $r7;
	shl.u32 $r4, $r0, 0x00000002;
	and.b32 $r0, $r2, constant1_Z11mb_sad_calcPtS_ii[0x0008];
	shl.u32 $r1, $r3, 0x00000004;
	shl.u32 $r3, $r5, 0x00000004;
	add.half.u32 $r0, $r0, $r1;
	add.half.u32 $r1, $r3, $r4;
	add.u32 $r3, $r0, $r1;
	and.b32 $r1, $r9, constant1_Z11mb_sad_calcPtS_ii[0x0004];
	and.b32 $r0, $r2, constant1_Z11mb_sad_calcPtS_ii[0x0000];
	shl.u32 $r2, $r3, 0x00000001;
	add.half.u32 $r1, $r0, $r1;
	add.half.u32 $r0, s[0x0018], $r2;
	ld.global.u16 $r0, [$r0];
	shl.b32 $ofs1, $r1, 0x00000001;
	mov.u16 s[$ofs1+0x0028], $r0.lo;
	l0x00000150: nop;
	bra l0x00000168;
	l0x00000160: mov.u32 $r8, $r0;
	l0x00000168: nop;
	bar.sync 0x00000000;
	mov.u32 $r1, 0x4325c53f;
	mul.wide.u16 $r0, $r9.lo, $r1.hi;
	mad.wide.u16 $p0|$r0, $r9.hi, $r1.lo, $r0;
	shl.u32 $r2, $r0, 0x00000010;
	shr.u32 $r0, $r0, 0x00000010;
	mad.wide.u16 $p1|$o127, $r9.lo, $r1.lo, $r2;
	@$p0.cf add.u32 $r0, $r0, constant1_Z11mb_sad_calcPtS_ii[0x000c];
	madp.wide.u16 $r0, $r9.hi, $r1.hi, $r0, $p1;
	shr.u32 $r1, $r0, 0x00000004;
	add.u32 $r0, $r1, $r10;
	shr.u32 $r2, $r0, 0x00000002;
	set.gt.s32.s32 $p0/$o127, s[0x0024], $r2;
	shr.u32 $r2, $r8, 0x00000002;
	@$p0.ne set.gt.s32.s32 $p0/$o127, s[0x0020], $r2;
	ssy 0x00000618;
	@$p0.eq bra l0x00000618;
	mov.u32 $r3, 0x4325c53f;
	mul.wide.u16 $r2, $r9.lo, $r3.hi;
	mad.wide.u16 $p0|$r2, $r9.hi, $r3.lo, $r2;
	shl.u32 $r4, $r2, 0x00000010;
	shr.u32 $r2, $r2, 0x00000010;
	mad.wide.u16 $p1|$o127, $r9.lo, $r3.lo, $r4;
	@$p0.cf add.u32 $r2, $r2, constant1_Z11mb_sad_calcPtS_ii[0x000c];
	madp.wide.u16 $r2, $r9.hi, $r3.hi, $r2, $p1;
	mov.u32 $r3, 0x0000003d;
	shr.u32 $r2, $r2, 0x00000004;
	mul.wide.u16 $r4, $r2.lo, $r3.hi;
	mad.wide.u16 $r4, $r2.hi, $r3.lo, $r4;
	shl.u32 $r4, $r4, 0x00000010;
	mad.wide.u16 $r2, $r2.lo, $r3.lo, $r4;
	add.u32 $r2, -$r2, $r9;
	shl.u32 $r3, $r2, 0x00000004;
	shl.u32 $r2, $r2, 0x00000001;
	add.u32 $p0|$r2, $r3, $r2;
	mov.u32 $r5, 0x3e0f83e1;
	abs.u32 $r4, $r2;
	mul.wide.u16 $r3, $r4.lo, $r5.hi;
	mad.wide.u16 $p1|$r3, $r4.hi, $r5.lo, $r3;
	shl.u32 $r7, $r3, 0x00000010;
	shr.u32 $r3, $r3, 0x00000010;
	mad.wide.u16 $p2|$o127, $r4.lo, $r5.lo, $r7;
	@$p1.cf add.u32 $r3, $r3, constant1_Z11mb_sad_calcPtS_ii[0x000c];
	@$p3 mad.wide.u16 $r3, -$r4.hi, $r5.hi, $r3;
	shr.s32 $r3, $r3, 0x00000003;
	and.b32 $r5, $r0, constant1_Z11mb_sad_calcPtS_ii[0x0010];
	and.b32 $r0, $r0, constant1_Z11mb_sad_calcPtS_ii[0x0008];
	add.u32 $r4, -$r3, 0x00000000;
	add.u32 $r5, $r5, $r0;
	add.u32 $r0, $r2, 0x00000012;
	@$p0.sf mov.u32 $r3, $r4;
	shl.u32 $r5, $r5, 0x00000002;
	set.gt.s32.s32 $p0/$o127, $r0, constant1_Z11mb_sad_calcPtS_ii[0x0014];
	shl.u32 $r4, $r3, 0x00000005;
	@$p0.ne mov.u32 $r0, constant1_Z11mb_sad_calcPtS_ii[0x0014];
	add.half.u32 $r5, $r3, $r5;
	add.half.u32 $r3, $r3, $r4;
	set.le.s32.s32 $p0/$o127, $r0, $r2;
	add.u32 $r21, $r5, 0xfffffff0;
	add.u32 $r20, $r2, -$r3;
	@$p0.ne bra l0x00000618;
	mov.u32 $r3, 0x00000448;
	mul.wide.u16 $r4, $r1.lo, $r3.hi;
	mad.wide.u16 $r4, $r1.hi, $r3.lo, $r4;
	shl.u32 $r4, $r4, 0x00000010;
	and.b32 $r5, $r8, constant1_Z11mb_sad_calcPtS_ii[0x0010];
	and.b32 $r7, $r8, constant1_Z11mb_sad_calcPtS_ii[0x0008];
	mad.wide.u16 $r3, $r1.lo, $r3.lo, $r4;
	add.u32 $r1, $r1, $r124;
	add.half.u32 $r4, $r5, $r7;
	add.half.u32 $r22, $r3, $r2;
	add.u32 $r24, $r3, $r0;
	shl.u32 $r23, $r1, 0x00000004;
	shl.u32 $r25, $r4, 0x00000002;
	l0x000003b0: add.u32 $r0, $r25, $r20;
	mov.u32 $r19, $r124;
	mov.u32 $r15, $r124;
	mov.u32 $r14, $r124;
	mov.u32 $r7, $r124;
	add.u32 $r1, $r0, 0xfffffff0;
	add.u32 $r2, $r0, 0xfffffff1;
	add.u32 $r3, $r0, 0xfffffff2;
	add.u32 $r4, $r0, 0xfffffff3;
	add.u32 $r5, $r0, 0xfffffff4;
	add.u32 $r0, $r0, 0xfffffff5;
	cvt.f32.s32 $r11, $r1;
	cvt.f32.s32 $r12, $r2;
	cvt.f32.s32 $r13, $r3;
	cvt.f32.s32 $r16, $r4;
	cvt.f32.s32 $r17, $r5;
	cvt.f32.s32 $r18, $r0;
	l0x00000438: shl.u32 $r0, $r19, 0x00000002;
	add.half.u32 $r1, $r21, $r19;
	add.half.u32 $r0, $r23, $r0;
	cvt.f32.s32 $r26, $r1;
	shl.b32 $ofs1, $r0, 0x00000001;
	mov.half.u32 $r4, $r11;
	mov.half.u32 $r0, $r12;
	mov.half.u32 $r5, $r26;
	mov.half.u32 $r2, $r13;
	mov.half.u32 $r1, $r26;
	mov.half.u32 $r3, $r26;
	tex.1d.v4.f32.s32 { $r4,_,_,_} , ref,{ $r4,_,_,_};
	tex.1d.v4.f32.s32 { $r0,_,_,_} , ref,{ $r0,_,_,_};
	tex.1d.v4.f32.s32 { $r2,_,_,_} , ref,{ $r2,_,_,_};
	cvt.u32.u16 $r27, s[$ofs1+0x0028];
	cvt.u32.u16 $r4, $r4.lo;
	sad.s32 $r4, $r4, $r27, $r7;
	cvt.u32.u16 $r1, s[$ofs1+0x002a];
	cvt.u32.u16 $r0, $r0.lo;
	cvt.u32.u16 $r3, s[$ofs1+0x0028];
	sad.s32 $r4, $r0, $r1, $r4;
	sad.s32 $r5, $r0, $r3, $r14;
	cvt.u32.u16 $r3, s[$ofs1+0x002c];
	cvt.u32.u16 $r1, $r2.lo;
	cvt.u32.u16 $r2, s[$ofs1+0x002a];
	cvt.u32.u16 $r0, s[$ofs1+0x0028];
	sad.s32 $r27, $r1, $r3, $r4;
	sad.s32 $r28, $r1, $r2, $r5;
	sad.s32 $r14, $r1, $r0, $r15;
	mov.half.u32 $r4, $r16;
	mov.half.u32 $r0, $r17;
	mov.half.u32 $r5, $r26;
	mov.half.u32 $r2, $r18;
	mov.half.u32 $r1, $r26;
	mov.half.u32 $r3, $r26;
	tex.1d.v4.f32.s32 { $r4,_,_,_} , ref,{ $r4,_,_,_};
	tex.1d.v4.f32.s32 { $r0,_,_,_} , ref,{ $r0,_,_,_};
	tex.1d.v4.f32.s32 { $r2,_,_,_} , ref,{ $r2,_,_,_};
	cvt.u32.u16 $r7, s[$ofs1+0x002a];
	cvt.u32.u16 $r4, $r4.lo;
	sad.s32 $r5, $r4, $r7, $r14;
	cvt.u32.u16 $r1, s[$ofs1+0x002c];
	cvt.u32.u16 $r7, s[$ofs1+0x002c];
	cvt.u32.u16 $r3, $r0.lo;
	sad.s32 $r14, $r4, $r1, $r28;
	sad.s32 $r15, $r3, $r7, $r5;
	add.u32 $r19, $r19, 0x00000001;
	cvt.u32.u16 $r0, s[$ofs1+0x002e];
	cvt.u32.u16 $r1, s[$ofs1+0x002e];
	cvt.u32.u16 $r5, s[$ofs1+0x002e];
	cvt.u32.u16 $r2, $r2.lo;
	set.ne.s32.s32 $p0/$o127, $r19, constant1_Z11mb_sad_calcPtS_ii[0x0018];
	sad.s32 $r7, $r4, $r0, $r27;
	sad.s32 $r14, $r3, $r1, $r14;
	sad.s32 $r15, $r2, $r5, $r15;
	@$p0.ne bra l0x00000438;
	shl.b32 $ofs1, $r22, 0x00000001;
	mov.u16 s[$ofs1+0x0050], $r7.lo;
	add.u32 $r20, $r20, 0x00000003;
	mov.u16 s[$ofs1+0x0052], $r14.lo;
	set.le.s32.s32 $p0/$o127, $r20, constant1_Z11mb_sad_calcPtS_ii[0x001c];
	mov.u16 s[$ofs1+0x0054], $r15.lo;
	@$p0.equ add.u32 $r20, $r20, constant1_Z11mb_sad_calcPtS_ii[0x002c];
	@$p0.equ add.u32 $r21, $r21, constant1_Z11mb_sad_calcPtS_ii[0x0030];
	add.u32 $r22, $r22, 0x00000003;
	set.lt.s32.s32 $p0/$o127, $r22, $r24;
	@$p0.ne bra l0x000003b0;
	l0x00000618: nop;
	bar.sync 0x00000000;
	shr.u32 $p0|$r2, $r9, 0x00000005;
	@$p0.ne retp;
	add.u32 $r0, $r2, $r10;
	shr.u32 $r1, $r0, 0x00000002;
	shr.u32 $r3, $r8, 0x00000002;
	set.gt.s32.s32 $p0/$o127, s[0x0024], $r1;
	@$p0.ne set.gt.s32.s32 $p0/$o127, s[0x0020], $r3;
	@$p0.eq retp;
	cvt.u32.u16 $r4, $r6.lo;
	and.b32 $r4, $r4, constant1_Z11mb_sad_calcPtS_ii[0x0020];
	set.gt.s32.s32 $p0/$o127, $r4, constant1_Z11mb_sad_calcPtS_ii[0x0024];
	@$p0.ne retp;
	and.b32 $r5, $r0, constant1_Z11mb_sad_calcPtS_ii[0x0008];
	mad24.lo.u32 $r1, s[0x0020], $r1, $r3;
	mov.u32 $r0, s[0x0020];
	and.b32 $r3, $r8, constant1_Z11mb_sad_calcPtS_ii[0x0008];
	shl.u32 $r5, $r5, 0x00000002;
	shl.u32 $r1, $r1, 0x00000004;
	mul24.lo.u32 $r6, s[0x0024], $r0;
	add.half.u32 $r0, $r5, $r3;
	mad24.lo.u32 $r1, $r6, constant1_Z11mb_sad_calcPtS_ii[0x0028], $r1;
	add.u32 $r0, $r0, $r1;
	mov.u32 $r1, 0x00000448;
	mul.wide.u16 $r3, $r0.lo, $r1.hi;
	mad.wide.u16 $r3, $r0.hi, $r1.lo, $r3;
	mov.u32 $r5, 0x00000112;
	shl.u32 $r3, $r3, 0x00000010;
	mul.wide.u16 $r6, $r2.lo, $r5.hi;
	mad.wide.u16 $r0, $r0.lo, $r1.lo, $r3;
	mad.wide.u16 $r1, $r2.hi, $r5.lo, $r6;
	shl.u32 $r0, $r0, 0x00000001;
	shl.u32 $r3, $r1, 0x00000010;
	shl.u32 $r1, $r4, 0x00000003;
	add.u32 $r0, s[0x0010], $r0;
	mad.wide.u16 $r5, $r2.lo, $r5.lo, $r3;
	add.half.u32 $r2, $r0, $r1;
	add.half.u32 $r3, $r4, $r5;
	add.u32 $r4, $r5, 0x00000111;
	l0x00000748: shl.b32 $ofs1, $r3, 0x00000003;
	mov.u32 $r0, s[$ofs1+0x0050];
	mov.u32 $r1, s[$ofs1+0x0054];
	add.u32 $r3, $r3, 0x00000020;
	st.global.v2.u32 [$r2], {$r0,$r1};
	set.le.s32.s32 $p0/$o127, $r3, $r4;
	add.u32 $r2, $r2, 0x00000100;
	@$p0.ne bra l0x00000748;
	nop;

	l_exit: exit;
}
