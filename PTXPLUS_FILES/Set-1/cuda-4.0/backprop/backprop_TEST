//HEADER
.version 1.4+
.target sm_10, map_f64_to_f32
//END HEADER


//INSTRUCTIONS

.const .u32 constant1_Z22bpnn_layerforward_CUDAPfS_S_S_ii[3] = {
          0x000003ff, 0x00000001, 0x40800000
};

.const .u32 constant1_Z24bpnn_adjust_weights_cudaPfiS_iS_S_[2] = {
          0x000003ff, 0x3e99999a
};





.entry  _Z24bpnn_adjust_weights_cudaPfiS_iS_S_ (
	.param  .u64 __cudaparm__Z24bpnn_adjust_weights_cudaPfiS_iS_S__delta ,
	.param  .s32 __cudaparm__Z24bpnn_adjust_weights_cudaPfiS_iS_S__hid ,
	.param  .u64 __cudaparm__Z24bpnn_adjust_weights_cudaPfiS_iS_S__ly ,
	.param  .s32 __cudaparm__Z24bpnn_adjust_weights_cudaPfiS_iS_S__in ,
	.param  .u64 __cudaparm__Z24bpnn_adjust_weights_cudaPfiS_iS_S__w ,
	.param  .u64 __cudaparm__Z24bpnn_adjust_weights_cudaPfiS_iS_S__oldw )
{
	
	.reg .u32 $r3;
	.reg .u32 $r2;	
	.reg .u32 $r1;
	.reg .u32 $r0;	
	.reg .u32 $r4;	
	.reg .u32 $r5;
	.reg .u32 $r6;	
	.reg .u32 $r8;
	.reg .u32 $r7;	
	.reg .u32 $r10;
	.reg .u32 $r11;	
	.reg .u32 $r9;	
	.reg .pred $p0;		
	.reg .u32 $o127;
	.reg .u32 $r124;
	.reg .pred $p1;
	.reg .pred $p2;
	.reg .pred $p3;	

	
	add.u32 $r3, s[0x0018], 0x00000001;
	shl.u32 $r2, s[0x0018], 0x00000004;
	cvt.u32.u16 $r1, %ctaid.y;
	and.u16 $r0.hi, $r0.hi, constant1_Z24bpnn_adjust_weights_cudaPfiS_iS_S_[0x0000];
	add.u32 $r4, $r2, 0x00000010;
	cvt.u32.u16 $r2, $r0.hi;
	mul.half.lo.u16 $r5, $r3.lo, $r2.hi;
	mul.half.lo.u16 $r6, $r4.lo, $r1.hi;
	mad.wide.u16 $r5, $r3.hi, $r2.lo, $r5;
	mad.wide.u16 $r6, $r4.hi, $r1.lo, $r6;
	shl.u32 $r5, $r5, 0x00000010;
	shl.u32 $r6, $r6, 0x00000010;
	mad.wide.u16 $r3, $r3.lo, $r2.lo, $r5;
	mad.wide.u16 $r4, $r4.lo, $r1.lo, $r6;
	add.u32 $r3, $r3, $r4;
	cvt.u32.u16 $r0, $r0.lo;
	shl.u32 $r4, $r1, 0x00000004;
	add.half.u32 $r3, $r0, $r3;
	add.half.u32 $r5, $r2, $r4;
	add.u32 $r4, s[0x0018], $r3;
	shl.u32 $r3, $r0, 0x00000002;
	shl.u32 $r5, $r5, 0x00000002;
	shl.u32 $r4, $r4, 0x00000002;
	add.half.u32 $r0, s[0x0010], $r3;
	add.half.u32 $r5, s[0x0020], $r5;
	add.half.u32 $r8, s[0x0038], $r4;
	add.half.u32 $r7, s[0x0030], $r4;
	add.u32 $r6, $r0, 0x00000004;
	ld.global.u32 $r10, [$r6];
	add.u32 $r5, $r5, 0x00000004;
	add.u32 $r4, $r8, 0x00000008;
	ld.global.u32 $r11, [$r4];
	ld.global.u32 $r9, [$r5];
	add.u32 $r7, $r7, 0x00000008;
	ld.global.u32 $r8, [$r7];
	cvt.f32.f32 $r10, $r10;
	cvt.f32.f32 $r11, $r11;
	mul.f32 $r10, $r10, 0x3e99999a;
	cvt.f32.f32 $r9, $r9;
	mul.f32 $r11, $r11, 0x3e99999a;
	mad.f32 $r9, $r9, $r10, $r11;
	cvt.f32.f32 $r8, $r8;
	add.f32 $r8, $r8, $r9;
	st.global.u32 [$r7], $r8;
	ld.global.u32 $r7, [$r6];
	ld.global.u32 $r6, [$r4];
	ld.global.u32 $r5, [$r5];
	cvt.f32.f32 $r7, $r7;
	cvt.f32.f32 $r8, $r6;
	cvt.f32.f32 $r5, $r5;
	mul.f32 $r6, $r7, 0x3e99999a;
	mul.f32 $r7, $r8, 0x3e99999a;
	mad.f32 $r5, $r5, $r6, $r7;
	st.global.u32 [$r4], $r5;
	bar.sync 0x00000000;
	set.eq.s32.s32 $p0/$o127, $r2, $r124;
	@$p0.ne set.eq.s32.s32 $p0/$o127, $r1, $r124;
	@$p0.eq retp;
	add.half.u32 $r1, s[0x0038], $r3;
	add.half.u32 $r4, s[0x0030], $r3;
	add.u32 $r1, $r1, 0x00000004;
	ld.global.u32 $r3, [$r1];
	add.u32 $r2, $r0, 0x00000004;
	ld.global.u32 $r0, [$r2];
	add.u32 $r5, $r4, 0x00000004;
	ld.global.u32 $r4, [$r5];
	cvt.f32.f32 $r3, $r3;
	cvt.f32.f32 $r6, $r0;
	mul.f32 $r0, $r3, 0x3e99999a;
	mad.f32 $r0, $r6, 0x3e99999a, $r0;
	cvt.f32.f32 $r3, $r4;
	add.f32 $r0, $r3, $r0;
	st.global.u32 [$r5], $r0;
	ld.global.u32 $r3, [$r1];
	ld.global.u32 $r0, [$r2];
	cvt.f32.f32 $r2, $r3;
	cvt.f32.f32 $r3, $r0;
	mul.f32 $r0, $r2, 0x3e99999a;
	mad.f32 $r0, $r3, 0x3e99999a, $r0;
	st.global.u32 [$r1], $r0;

	l_exit: exit;
}
