//HEADER
.version 1.4+
.target sm_10, map_f64_to_f32
//END HEADER


//INSTRUCTIONS

.const .u32 constant0[114] = {
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000, 0x00000000, 0x00000000, 
          0x00000000, 0x00000000
};

.const .u32 constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[6] = {
          0x00000fff, 0x3f000000, 0x7e800000, 0xc2c80000, 
          0x3f800000, 0x3e800000
};

.const .u32 constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[7] = {
          0x00000fff, 0x3f000000, 0x3f800000, 0xc2c80000, 
          0x7e800000, 0xffffffff, 0x3e800000
};



.const .b8 maturities[60];
.constptr maturities, constant0, 16;
.const .b8 N[4];
.constptr N, constant0, 0;
.const .b8 delta[4];
.constptr delta, constant0, 12;
.const .b8 lambda[320];
.constptr lambda, constant0, 136;
.const .b8 Nopt[4];
.constptr Nopt, constant0, 8;
.const .b8 Nmat[4];
.constptr Nmat, constant0, 4;
.const .b8 swaprates[60];
.constptr swaprates, constant0, 76;

.local .b8 l1[0];
.local .b8 l2[0];

.entry  _Z28Pathcalc_Portfolio_KernelGPUPfS_ (
	.param  .u64 __cudaparm__Z28Pathcalc_Portfolio_KernelGPUPfS__d_v ,
	.param  .u64 __cudaparm__Z28Pathcalc_Portfolio_KernelGPUPfS__d_Lb )
{

	.reg .u32 $r0;
	.reg .u32 $r1;
	.reg .pred $p0;
	.reg .u32 $o127;
	.reg .pred $p1;
	.reg .u32 $r124;	
	.reg .u32 $r2;
	.reg .u32 $r4;
	.reg .u32 $r3;	
	.reg .u32 $r10;
	.reg .u32 $r11;	
	.reg .u32 $r9;
	.reg .u32 $r7;	
	.reg .u32 $r12;
	.reg .u32 $r8;	
	.reg .pred $p2;
	.reg .u32 $ofs2;
	.reg .u32 $ofs1;	
	.reg .pred $p3;	
	.reg .u32 $r5;
	.reg .u32 $r6;
	.reg .u32 $r14;
	.reg .u32 $r13;
	.reg .u32 $r15;	
	.reg .u32 $r16;
	.reg .u32 $r17;	
	.reg .u32 $ofs3;
	.reg .u32 $ofs4;
	.reg .u32 $ofs0;
	
	mov.u16 $r0.hi, %ntid.x;
	cvt.u32.u16 $r1, $r0.lo;
	mad.wide.u16 $r1, %ctaid.x, $r0.hi, $r1;
	set.gt.s32.s32 $p0/$o127, $r1, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0000];
	@$p0.ne retp;
	set.lt.s32.s32 $p1/$o127, $r124, constant0[0x0004];
	mov.u32 $r2, constant0[0x0000];
	mov.u32 $r4, 0xffffffff;
	mov.u16 $r0.lo, %ntid.x;
	shl.u32 $r3, $r1, 0x00000002;
	add.half.u32 $r10, $r2, -constant0[0x0004];
	add.half.u32 $r2, $r4, constant0[0x0004];
	mul.half.lo.u16 $r11, %nctaid.x, $r0.lo;
	add.half.u32 $r9, s[0x0010], $r3;
	add.u32 $r7, s[0x0018], $r3;
	add.u32 $r12, $r10, 0xffffffff;
	shl.u32 $r8, $r11, 0x00000002;
	set.lt.s32.s32 $p0/$o127, $r124, constant0[0x0000];
	set.gt.s32.s32 $p2/$o127, $r10, $r124;
	l0x00000088: @$p0.eq bra l0x00000168;
	mov.u32 $r3, 0x000035c0;
	mov.u32 $r0, 0x00003700;
	shl.b32 $ofs2, $r3, 0x0;
	shl.b32 $ofs1, $r0, 0x0;
	mov.u32 $r0, $r124;
	l0x000000b8: mov.u32 $r3, 0x3e99999a;
	st.local.u32 [$ofs2+0x0000], $r3;
	mov.u32 $r3, 0x3d4ccccd;
	st.local.u32 [$ofs1+0x0000], $r3;
	add.u32 $r0, $r0, 0x00000001;
	add.u32 $ofs2, $ofs2, 0x00000004;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r0, constant0[0x0000];
	@$p3.ne bra l0x000000b8;
	@$p0.eq bra l0x00000168;
	mov.u32 $r3, 0x00003700;
	mov.u32 $r0, 0x00000140;
	shl.b32 $ofs2, $r3, 0x0;
	shl.b32 $ofs1, $r0, 0x0;
	mov.u32 $r0, $r124;
	l0x00000130: ld.local.u32 $r3, [$ofs2+0x0000];
	st.local.u32 [$ofs1+0x0000], $r3;
	add.u32 $r0, $r0, 0x00000001;
	add.u32 $ofs2, $ofs2, 0x00000004;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r0, constant0[0x0000];
	@$p3.ne bra l0x00000130;
	l0x00000168: @$p1.eq bra l0x00000308;
	mov.u32 $r0, $r124;
	l0x00000178: add.u32 $r4, $r0, 0x00000001;
	mov.u32 $r3, $r4;
	set.ge.s32.s32 $p3/$o127, $r4, constant0[0x0000];
	@$p3.ne bra l0x000002f0;
	mov.u32 $r5, constant0[0x0000];
	mul.wide.u16 $r6, $r5.lo, $r0.hi;
	mad.wide.u16 $r6, $r5.hi, $r0.lo, $r6;
	shl.u32 $r6, $r6, 0x00000010;
	add.u32 $r14, $r3, 0x00000dc0;
	shl.b32 $ofs2, $r0, 0x00000002;
	ld.local.u32 $r13, [$ofs2+0x35c0];
	mad.wide.u16 $r6, $r5.lo, $r0.lo, $r6;
	shl.b32 $ofs1, $r14, 0x00000002;
	mov.u32 $r5, constant0[0x000c];
	rsqrt.f32 $r5, $r5;
	rcp.half.f32 $r5, $r5;
	mul.half.f32 $r5, $r5, $r13;
	mov.u32 $r15, $r124;
	cvt.f32.f32 $r5, $r5;
	add.u32 $r14, $r6, constant0[0x0000];
	l0x00000210: ld.local.u32 $r16, [$ofs1+0x0000];
	add.u32 $r6, $r4, -$r0;
	shl.b32 $ofs2, $r6, 0x00000002;
	mov.u32 $r6, constant0[0x000c];
	mul.f32 $r17, $r6, constant0[$ofs2+0x0084];
	mul.f32 $r6, $r16, constant0[0x000c];
	cvt.f32.f32 $r6, $r6;
	add.f32 $r13, $r6, 0x3f800000;
	mul.half.f32 $r6, $r17, $r16;
	rcp.half.f32 $r13, $r13;
	mad.f32 $r15, $r6, $r13, $r15;
	mov.u32 $r13, constant0[$ofs2+0x0084];
	cvt.f32.f32 $r6, $r17;
	mul.f32 $r17, $r15, $r17;
	cvt.f32.f32 $r13, $r13;
	mad.f32 $r6, -$r6, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0004], $r5;
	cvt.f32.f32 $r17, $r17;
	mad.f32 $r6, $r13, $r6, $r17;
	mul.f32 $r6, $r6, 0x3fb8aa3b;
	nop; //ex2.f32 $r6, $r6;
	ex2.f32 $r6, $r6;
	mul.half.f32 $r6, $r16, $r6;
	add.half.u32 $r13, $r4, $r14;
	shl.b32 $ofs2, $r13, 0x00000002;
	st.local.u32 [$ofs1+0x0000], $r6;
	add.u32 $r4, $r4, 0x00000001;
	st.local.u32 [$ofs2+0x0140], $r6;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r4, constant0[0x0000];
	@$p3.ne bra l0x00000210;
	l0x000002f0: mov.u32 $r0, $r3;
	set.ne.s32.s32 $p3/$o127, $r3, constant0[0x0004];
	@$p3.ne bra l0x00000178;
	l0x00000308: @$p2.eq bra l0x00000438;
	mov.u32 $r0, 0x00000dc0;
	mov.u32 $r4, 0x00003520;
	mov.u32 $r3, 0x000000a0;
	add.u32 $r0, $r0, constant0[0x0004];
	shl.b32 $ofs3, $r4, 0x0;
	shl.b32 $ofs2, $r3, 0x0;
	shl.b32 $ofs1, $r0, 0x00000002;
	mov.u32 $r0, constant0[0x0004];
	mov.u32 $r3, $r124;
	mov.u32 $r4, 0x3f800000;
	l0x00000360: ld.local.u32 $r5, [$ofs1+0x0000];
	mul.f32 $r5, $r5, constant0[0x000c];
	cvt.f32.f32 $r5, $r5;
	add.f32 $r5, $r5, 0x3f800000;
	rcp.half.f32 $r5, $r5;
	mul.half.f32 $r4, $r4, $r5;
	mad.f32 $r3, $r4, constant0[0x000c], $r3;
	st.local.u32 [$ofs3+0x0000], $r4;
	st.local.u32 [$ofs2+0x0000], $r3;
	add.u32 $r0, $r0, 0x00000001;
	add.u32 $ofs1, $ofs1, 0x00000004;
	add.u32 $ofs3, $ofs3, 0x00000004;
	add.u32 $ofs2, $ofs2, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r0, constant0[0x0000];
	@$p3.ne bra l0x00000360;
	@$p2.eq bra l0x00000438;
	mov.u32 $r0, 0x00003480;
	shl.b32 $ofs2, $r0, 0x0;
	shl.b32 $ofs1, $r124, 0x0;
	mov.u32 $r0, $r124;
	l0x000003f8: mov.u32 $r3, 0x00000000;
	st.local.u32 [$ofs2+0x0000], $r3;
	st.local.u32 [$ofs1+0x0000], $r3;
	add.u32 $r0, $r0, 0x00000001;
	add.u32 $ofs2, $ofs2, 0x00000004;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r10, $r0;
	@$p3.ne bra l0x000003f8;
	l0x00000438: set.lt.s32.s32 $p3/$o127, $r124, constant0[0x0008];
	@$p3.eq bra l0x00000558;
	mov.u32 $r0, 0x0000004c;
	mov.u32 $r3, 0x00000010;
	shl.b32 $ofs1, $r0, 0x0;
	shl.b32 $ofs2, $r3, 0x0;
	mov.u32 $r4, $r124;
	mov.u32 $r3, $r124;
	l0x00000478: mov.u32 $r0, constant0[$ofs2+0x0000];
	shl.b32 $ofs3, $r0, 0x00000002;
	ld.local.u32 $r5, [$ofs3+0x351c];
	ld.local.u32 $r0, [$ofs3+0x009c];
	mad.f32 $r0, $r0, constant0[$ofs1+0x0000], $r5;
	cvt.f32.f32 $r0, $r0;
	set.lt.f32.f32 $r13, $r0, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0008];
	ssy 0x00000528;
	mov.u32 $r5, constant0[$ofs1+0x0000];
	add.f32 $r6, $r0, 0xbf800000;
	cvt.s32.s32 $p3|$o127, $r13;
	@$p3.eq bra l0x00000528;
	mov.u32 $r0, $ofs3;
	add.u32 $r0, $r0, 0xfffffffc;
	shl.b32 $ofs4, $r0, 0x0;
	ld.local.u32 $r0, [$ofs4+0x0000];
	mad.f32 $r3, $r6, 0xc2c80000, $r3;
	mad.f32 $r0, $r5, 0xc2c80000, $r0;
	st.local.u32 [$ofs4+0x0000], $r0;
	ld.local.u32 $r0, [$ofs3+0x347c];
	add.f32 $r0, $r0, 0xc2c80000;
	st.local.u32 [$ofs3+0x347c], $r0;
	l0x00000528: add.u32 $ofs2, $ofs2, 0x00000004;
	add.u32 $r4, $r4, 0x00000001;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r4, constant0[0x0008];
	@$p3.ne bra l0x00000478;
	bra l0x00000560;
	l0x00000558: mov.u32 $r3, $r124;
	l0x00000560: mov.u32 $r12, constant0[0x0000];
	add.u32 $r12, $r12, -constant0[0x0004];
	add.u32 $r12, $r12, 0xffffffff;
	set.ge.s32.s32 $p3/$o127, $r12, $r124;
	@$p3.eq bra l0x00000718;
	add.u32 $r0, $r12, constant0[0x0004];
	add.u32 $r6, $r12, 0x00000d20;
	add.u32 $r4, $r12, 0x00000d48;
	add.u32 $r5, $r0, 0x00000dc0;
	shl.b32 $ofs4, $r6, 0x00000002;
	shl.b32 $ofs2, $r4, 0x00000002;
	mov.u32 $r4, $ofs2;
	shl.b32 $ofs1, $r5, 0x00000002;
	shl.b32 $ofs3, $r12, 0x00000002;
	l0x000005d0: ld.local.u32 $r5, [$ofs3+0x0000];
	ld.local.u32 $r6, [$ofs4+0x0000];
	mad.f32 $r6, $r5, constant0[0x000c], $r6;
	st.local.u32 [$ofs4+0x0000], $r6;
	ld.local.u32 $r14, [$ofs1+0x0000];
	shl.b32 $ofs2, $r4, 0x0;
	ld.local.u32 $r13, [$ofs2+0x0000];
	mul.f32 $r14, $r14, constant0[0x000c];
	cvt.f32.f32 $r14, $r14;
	add.f32 $r14, $r14, 0x3f800000;
	rcp.half.f32 $r14, $r14;
	mul.half.f32 $r15, $r6, $r13;
	mul.half.f32 $r13, $r14, constant0[0x000c];
	mul.half.f32 $r13, $r13, $r15;
	cvt.f32.f32 $r13, -$r13;
	st.local.u32 [$ofs1+0x0000], $r13;
	set.le.s32.s32 $p3/$o127, $r0, constant0[0x0004];
	@$p3.ne bra l0x000006d0;
	mov.u32 $r14, $ofs3;
	add.u32 $r14, $r14, 0xfffffffc;
	shl.b32 $ofs2, $r14, 0x0;
	ld.local.u32 $r14, [$ofs2+0x0000];
	add.f32 $r5, $r14, $r5;
	st.local.u32 [$ofs2+0x0000], $r5;
	mul.f32 $r13, $r13, constant0[0x000c];
	mov.u32 $r5, $ofs4;
	cvt.f32.f32 $r13, $r13;
	add.u32 $r5, $r5, 0xfffffffc;
	add.f32 $r13, $r13, 0x3f800000;
	rcp.f32 $r13, $r13;
	shl.b32 $ofs2, $r5, 0x0;
	ld.local.u32 $r5, [$ofs2+0x0000];
	mad.f32 $r5, $r6, $r13, $r5;
	st.local.u32 [$ofs2+0x0000], $r5;
	l0x000006d0: shl.b32 $ofs2, $r4, 0x0;
	add.u32 $ofs2, $ofs2, 0x0000fffc;
	mov.u32 $r4, $ofs2;
	add.u32 $r0, $r0, 0xffffffff;
	add.u32 $ofs3, $ofs3, 0x0000fffc;
	add.u32 $ofs4, $ofs4, 0x0000fffc;
	add.u32 $ofs1, $ofs1, 0x0000fffc;
	set.ne.s32.s32 $p3/$o127, $r0, $r2;
	@$p3.ne bra l0x000005d0;
	l0x00000718: @$p1.eq bra l0x000007b0;
	mov.u32 $r0, 0x00003700;
	shl.b32 $ofs1, $r0, 0x0;
	mov.u32 $r4, $r124;
	mov.u32 $r0, 0x3f800000;
	l0x00000740: ld.local.u32 $r5, [$ofs1+0x0000];
	mul.f32 $r5, $r5, constant0[0x000c];
	cvt.f32.f32 $r5, $r5;
	add.f32 $r5, $r5, 0x3f800000;
	set.abs.gt.f32.f32 $p3/$o127, $r5, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0010];
	@$p3.neu mul.f32 $r0, $r0, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0018];
	@$p3.neu mul.f32 $r5, $r5, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0018];
	rcp.f32 $r5, $r5;
	add.u32 $r4, $r4, 0x00000001;
	mul.f32 $r0, $r0, $r5;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r4, constant0[0x0004];
	@$p3.ne bra l0x00000740;
	bra l0x000007b8;
	l0x000007b0: mov.u32 $r0, 0x3f800000;
	l0x000007b8: mul.f32 $r5, $r3, $r0;
	@$p1.eq bra l0x00000860;
	mov.u32 $r3, 0x00003700;
	mul.f32 $r4, $r5, constant0[0x000c];
	shl.b32 $ofs1, $r3, 0x0;
	mov.u32 $r6, $r124;
	cvt.f32.f32 $r3, -$r4;
	l0x000007f0: ld.local.u32 $r4, [$ofs1+0x0000];
	mul.f32 $r4, $r4, constant0[0x000c];
	cvt.f32.f32 $r4, $r4;
	add.f32 $r13, $r4, 0x3f800000;
	mov.u32 $r4, $r3;
	set.abs.gt.f32.f32 $p3/$o127, $r13, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0010];
	@$p3.neu mul.f32 $r4, $r4, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0018];
	@$p3.neu mul.f32 $r13, $r13, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0018];
	rcp.half.f32 $r13, $r13;
	mul.half.f32 $r4, $r4, $r13;
	st.local.u32 [$ofs1+0x0000], $r4;
	add.u32 $r6, $r6, 0x00000001;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r6, constant0[0x0004];
	@$p3.ne bra l0x000007f0;
	l0x00000860: mov.u32 $r3, constant0[0x0004];
	mov.u32 $r4, constant0[0x0004];
	set.lt.s32.s32 $p3/$o127, $r4, constant0[0x0000];
	@$p3.eq bra l0x000008d0;
	mov.u32 $r4, 0x00000dc0;
	add.u32 $r4, $r4, constant0[0x0004];
	shl.b32 $ofs1, $r4, 0x00000002;
	l0x00000898: ld.local.u32 $r4, [$ofs1+0x0000];
	mul.f32 $r4, $r4, $r0;
	st.local.u32 [$ofs1+0x0000], $r4;
	add.u32 $r3, $r3, 0x00000001;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r3, constant0[0x0000];
	@$p3.ne bra l0x00000898;
	l0x000008d0: st.global.u32 [$r9], $r5;
	mov.u32 $r0, $r2;
	mov.u32 $r2, 0xffffffff;
	add.u32 $r2, $r2, constant0[0x0004];
	set.ge.s32.s32 $p3/$o127, $r2, $r124;
	@$p3.eq bra l0x00000a88;
	mov.u32 $r3, 0xffffffff;
	add.u32 $r4, $r3, constant0[0x0000];
	l0x00000910: set.le.s32.s32 $p3/$o127, $r4, $r0;
	@$p3.ne bra l0x00000a70;
	mov.u32 $r3, constant0[0x0000];
	mul.wide.u16 $r5, $r3.lo, $r0.hi;
	mad.wide.u16 $r5, $r3.hi, $r0.lo, $r5;
	shl.u32 $r5, $r5, 0x00000010;
	mad.wide.u16 $r5, $r3.lo, $r0.lo, $r5;
	add.half.u32 $r6, $r5, constant0[0x0000];
	add.half.u32 $r3, $r4, -$r0;
	add.half.u32 $r13, $r4, $r5;
	add.half.u32 $r5, $r4, $r6;
	add.u32 $r15, $r4, 0x00000dc0;
	add.u32 $r14, $r3, 0x00000022;
	add.u32 $r6, $r13, 0x00000050;
	add.u32 $r5, $r5, 0x00000050;
	shl.b32 $ofs4, $r15, 0x00000002;
	shl.b32 $ofs3, $r14, 0x00000002;
	shl.b32 $ofs2, $r6, 0x00000002;
	shl.b32 $ofs1, $r5, 0x00000002;
	mov.u32 $r6, $ofs1;
	mov.u32 $r5, $r124;
	l0x000009a8: mov.u32 $r13, $ofs3;
	add.u32 $r16, $r13, 0xfffffffc;
	shl.b32 $ofs1, $r6, 0x0;
	ld.local.u32 $r15, [$ofs1+0x0000];
	ld.local.u32 $r14, [$ofs4+0x0000];
	ld.local.u32 $r13, [$ofs2+0x0000];
	shl.b32 $ofs1, $r16, 0x0;
	mul.f32 $r16, $r15, constant0[$ofs1+0x0000];
	mad.f32 $r5, $r14, $r16, $r5;
	rcp.half.f32 $r16, $r13;
	mul.half.f32 $r15, $r15, $r16;
	mul.half.f32 $r16, $r5, constant0[$ofs1+0x0000];
	mul.half.f32 $r13, $r13, constant0[0x000c];
	cvt.f32.f32 $r13, $r13;
	add.f32 $r13, $r13, 0x3f800000;
	rcp.half.f32 $r13, $r13;
	mul.half.f32 $r13, $r13, constant0[0x000c];
	mul.half.f32 $r16, $r13, $r16;
	mul.half.f32 $r13, $r13, $r16;
	mad.f32 $r13, $r14, $r15, $r13;
	st.local.u32 [$ofs4+0x0000], $r13;
	shl.b32 $ofs1, $r6, 0x0;
	add.u32 $ofs1, $ofs1, 0x0000fffc;
	mov.u32 $r6, $ofs1;
	add.u32 $ofs2, $ofs2, 0x0000fffc;
	add.u32 $ofs3, $ofs3, 0x0000fffc;
	add.u32 $ofs4, $ofs4, 0x0000fffc;
	add.u32 $p3|$r3, $r3, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0014];
	@$p3.ne bra l0x000009a8;
	l0x00000a70: add.u32 $r0, $r0, 0xffffffff;
	set.ne.s32.s32 $p3/$o127, $r0, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0014];
	@$p3.ne bra l0x00000910;
	l0x00000a88: ld.local.u32 $r0, [0x383c];
	st.global.u32 [$r7], $r0;
	add.half.u32 $r1, $r1, $r11;
	add.half.u32 $r9, $r9, $r8;
	add.u32 $r7, $r8, $r7;
	set.le.s32.s32 $p3/$o127, $r1, constant1_Z28Pathcalc_Portfolio_KernelGPUPfS_[0x0000];
	@$p3.ne bra l0x00000088;
	nop;

	l_exit: exit;
}

.entry  _Z29Pathcalc_Portfolio_KernelGPU2Pf (
	.param  .u64 __cudaparm__Z29Pathcalc_Portfolio_KernelGPU2Pf_d_v )
{
	.reg .u32 $r0;
	.reg .u32 $r1;
	.reg .pred $p0;
	.reg .u32 $o127;
	.reg .u32 $r2;
	.reg .pred $p1;
	.reg .u32 $r8;
	.reg .u32 $r124;
	.reg .pred $p2;
	.reg .u32 $r7;
	.reg .u32 $r6;
	.reg .pred $p3;
	.reg .u32 $ofs2;
	.reg .u32 $ofs1;
	.reg .u32 $r4;
	.reg .u32 $r5;
	.reg .u32 $r3;
	.reg .u32 $r9;
	.reg .u32 $r10;
	.reg .u32 $r11;
	.reg .u32 $r12;
	.reg .u32 $ofs3;
	.reg .u32 $ofs4;
	.reg .u32 $ofs0;

	
	mov.u16 $r0.hi, %ntid.x;
	cvt.u32.u16 $r1, $r0.lo;
	mad.wide.u16 $r0, %ctaid.x, $r0.hi, $r1;
	set.gt.s32.s32 $p0/$o127, $r0, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x0000];
	@$p0.ne retp;
	mov.u32 $r2, constant0[0x0004];
	mov.u16 $r1.lo, %ntid.x;
	set.lt.s32.s32 $p1/$o127, $r2, constant0[0x0000];
	shl.u32 $r2, $r0, 0x00000002;
	mul.wide.u16 $r8, %nctaid.x, $r1.lo;
	set.lt.s32.s32 $p0/$o127, $r124, constant0[0x0004];
	set.lt.s32.s32 $p2/$o127, $r124, constant0[0x0008];
	add.u32 $r7, s[0x0010], $r2;
	shl.u32 $r6, $r8, 0x00000002;
	l0x00000070: set.lt.s32.s32 $p3/$o127, $r124, constant0[0x0000];
	@$p3.eq bra l0x000000f0;
	mov.u32 $r2, 0x00000280;
	mov.u32 $r1, 0x000000a0;
	shl.b32 $ofs2, $r2, 0x0;
	shl.b32 $ofs1, $r1, 0x0;
	mov.u32 $r1, $r124;
	l0x000000a8: mov.u32 $r2, 0x3e99999a;
	st.local.u32 [$ofs2+0x0000], $r2;
	mov.u32 $r2, 0x3d4ccccd;
	st.local.u32 [$ofs1+0x0000], $r2;
	add.u32 $r1, $r1, 0x00000001;
	add.u32 $ofs2, $ofs2, 0x00000004;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r1, constant0[0x0000];
	@$p3.ne bra l0x000000a8;
	l0x000000f0: @$p0.eq bra l0x00000250;
	mov.u32 $r1, $r124;
	l0x00000100: add.u32 $r4, $r1, 0x00000001;
	mov.u32 $r2, $r4;
	set.ge.s32.s32 $p3/$o127, $r4, constant0[0x0000];
	@$p3.ne bra l0x00000238;
	add.u32 $r5, $r2, 0x00000028;
	shl.b32 $ofs2, $r1, 0x00000002;
	ld.local.u32 $r3, [$ofs2+0x0280];
	shl.b32 $ofs1, $r5, 0x00000002;
	mov.u32 $r5, constant0[0x000c];
	rsqrt.f32 $r5, $r5;
	rcp.half.f32 $r5, $r5;
	mul.half.f32 $r3, $r5, $r3;
	mov.u32 $r9, $r124;
	cvt.f32.f32 $r3, $r3;
	l0x00000168: ld.local.u32 $r10, [$ofs1+0x0000];
	add.u32 $r5, $r4, -$r1;
	shl.b32 $ofs2, $r5, 0x00000002;
	mov.u32 $r5, constant0[0x000c];
	mul.f32 $r11, $r5, constant0[$ofs2+0x0084];
	mul.f32 $r5, $r10, constant0[0x000c];
	cvt.f32.f32 $r5, $r5;
	add.f32 $r12, $r5, 0x3f800000;
	mul.half.f32 $r5, $r11, $r10;
	rcp.half.f32 $r12, $r12;
	mad.f32 $r9, $r5, $r12, $r9;
	mov.u32 $r12, constant0[$ofs2+0x0084];
	cvt.f32.f32 $r5, $r11;
	mul.f32 $r11, $r9, $r11;
	cvt.f32.f32 $r12, $r12;
	mad.f32 $r5, -$r5, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x0004], $r3;
	cvt.f32.f32 $r11, $r11;
	mad.f32 $r5, $r12, $r5, $r11;
	mul.f32 $r5, $r5, 0x3fb8aa3b;
	nop; //ex2.f32 $r5, $r5;
	ex2.f32 $r5, $r5;
	mul.f32 $r5, $r10, $r5;
	st.local.u32 [$ofs1+0x0000], $r5;
	add.u32 $r4, $r4, 0x00000001;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r4, constant0[0x0000];
	@$p3.ne bra l0x00000168;
	l0x00000238: mov.u32 $r1, $r2;
	set.ne.s32.s32 $p3/$o127, $r2, constant0[0x0004];
	@$p3.ne bra l0x00000100;
	l0x00000250: @$p1.eq bra l0x00000338;
	mov.u32 $r1, 0x00000028;
	mov.u32 $r2, 0x000001e0;
	add.u32 $r1, $r1, constant0[0x0004];
	shl.b32 $ofs1, $r2, 0x0;
	shl.b32 $ofs3, $r1, 0x00000002;
	shl.b32 $ofs2, $r124, 0x0;
	mov.u32 $r4, constant0[0x0000];
	mov.u32 $r3, $r124;
	mov.u32 $r2, $r124;
	mov.u32 $r1, 0x3f800000;
	add.u32 $r4, $r4, -constant0[0x0004];
	l0x000002b0: ld.local.u32 $r5, [$ofs3+0x0000];
	mul.f32 $r5, $r5, constant0[0x000c];
	cvt.f32.f32 $r5, $r5;
	add.f32 $r5, $r5, 0x3f800000;
	set.abs.gt.f32.f32 $p3/$o127, $r5, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x0008];
	@$p3.neu mul.f32 $r1, $r1, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x0014];
	@$p3.neu mul.f32 $r5, $r5, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x0014];
	rcp.half.f32 $r5, $r5;
	mul.half.f32 $r1, $r1, $r5;
	mad.f32 $r2, $r1, constant0[0x000c], $r2;
	st.local.u32 [$ofs2+0x0000], $r1;
	st.local.u32 [$ofs1+0x0000], $r2;
	add.u32 $r3, $r3, 0x00000001;
	add.u32 $ofs3, $ofs3, 0x00000004;
	add.u32 $ofs2, $ofs2, 0x00000004;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r3, $r4;
	@$p3.ne bra l0x000002b0;
	l0x00000338: @$p2.eq bra l0x00000410;
	mov.u32 $r1, 0x0000004c;
	mov.u32 $r2, 0x00000010;
	shl.b32 $ofs1, $r1, 0x0;
	shl.b32 $ofs2, $r2, 0x0;
	mov.u32 $r1, $r124;
	mov.u32 $r2, $r124;
	l0x00000370: mov.u32 $r3, constant0[$ofs2+=0x0004];
	shl.b32 $ofs3, $r3, 0x00000002;
	ld.local.u32 $r3, [$ofs3+0x01dc];
	mov.u32 $r4, $ofs3;
	add.u32 $r4, $r4, 0xfffffffc;
	shl.b32 $ofs4, $r4, 0x0;
	ld.local.u32 $r4, [$ofs4+0x0000];
	mad.f32 $r3, $r3, constant0[$ofs1+0x0000], $r4;
	cvt.f32.f32 $r3, $r3;
	add.f32 $r4, $r3, 0xbf800000;
	cvt.f32.f32 $r5, $r2;
	set.lt.f32.f32 $r9, $r3, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x0010];
	cvt.f32.f32 $r3, $r4;
	cvt.s32.s32 $p3|$o127, $r9;
	@$p3.ne mad.f32 $r2, $r3, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x000c], $r5;
	add.u32 $r1, $r1, 0x00000001;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r1, constant0[0x0008];
	@$p3.ne bra l0x00000370;
	bra l0x00000418;
	l0x00000410: mov.u32 $r2, $r124;
	l0x00000418: @$p0.eq bra l0x000004b0;
	mov.u32 $r1, 0x000000a0;
	shl.b32 $ofs1, $r1, 0x0;
	mov.u32 $r3, $r124;
	mov.u32 $r1, 0x3f800000;
	l0x00000440: ld.local.u32 $r4, [$ofs1+0x0000];
	mul.f32 $r4, $r4, constant0[0x000c];
	cvt.f32.f32 $r4, $r4;
	add.f32 $r4, $r4, 0x3f800000;
	set.abs.gt.f32.f32 $p3/$o127, $r4, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x0008];
	@$p3.neu mul.f32 $r1, $r1, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x0014];
	@$p3.neu mul.f32 $r4, $r4, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x0014];
	rcp.f32 $r4, $r4;
	add.u32 $r3, $r3, 0x00000001;
	mul.f32 $r1, $r1, $r4;
	add.u32 $ofs1, $ofs1, 0x00000004;
	set.ne.s32.s32 $p3/$o127, $r3, constant0[0x0004];
	@$p3.ne bra l0x00000440;
	bra l0x000004b8;
	l0x000004b0: mov.u32 $r1, 0x3f800000;
	l0x000004b8: mul.f32 $r1, $r2, $r1;
	st.global.u32 [$r7], $r1;
	add.half.u32 $r0, $r0, $r8;
	add.half.u32 $r7, $r7, $r6;
	set.le.s32.s32 $p3/$o127, $r0, constant1_Z29Pathcalc_Portfolio_KernelGPU2Pf[0x0000];
	@$p3.ne bra l0x00000070;
	nop;

	l_exit: exit;
}
//END INSTRUCTIONS
